{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "# https://docs.scipy.org/doc/numpy/reference/routines.math.html\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import tzinfo, timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from distutils.version import StrictVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "assert StrictVersion(sklearn.__version__ ) >= StrictVersion('0.18.1')\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "assert StrictVersion(tf.__version__) >= StrictVersion('1.1.0')\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.6'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "assert StrictVersion(keras.__version__) >= StrictVersion('2.0.0')\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !curl -O https://raw.githubusercontent.com/DJCordhose/speed-limit-signs/master/data/speed-limit-signs.zip\n",
    "# !curl -O https://raw.githubusercontent.com/DJCordhose/speed-limit-signs/master/data/augmented-signs.zip    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/zipfile.html\n",
    "# from zipfile import ZipFile\n",
    "# zip = ZipFile(r'speed-limit-signs.zip')\n",
    "# zip.extractall('.')\n",
    "# zip = ZipFile(r'augmented-signs.zip')\n",
    "# zip.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ls -l speed-limit-signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ls -l augmented-signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "def load_data(data_dir, type=\".ppm\"):\n",
    "    num_categories = 6\n",
    "\n",
    "    # Get all subdirectories of data_dir. Each represents a label.\n",
    "    directories = [d for d in os.listdir(data_dir) \n",
    "                   if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    # Loop through the label directories and collect the data in\n",
    "    # two lists, labels and images.\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_dir = os.path.join(data_dir, d)\n",
    "        file_names = [os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(type)]\n",
    "        # For each label, load it's images and add them to the images list.\n",
    "        # And add the label number (i.e. directory name) to the labels list.\n",
    "        for f in file_names:\n",
    "            images.append(skimage.data.imread(f))\n",
    "            labels.append(int(d))\n",
    "    images64 = [skimage.transform.resize(image, (64, 64)) for image in images]\n",
    "    y = np.array(labels)\n",
    "    y = to_categorical(y, num_categories)\n",
    "    X = np.array(images64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "ROOT_PATH = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_dir = os.path.join(ROOT_PATH, \"speed-limit-signs\")\n",
    "original_images, original_labels = load_data(original_dir, type=\".ppm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(ROOT_PATH, \"augmented-signs\")\n",
    "X, y = load_data(data_dir, type=\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = keras.callbacks.ModelCheckpoint('../tmp/model-checkpoints/weights.epoch-{epoch:02d}-val_loss-{val_loss:.2f}.hdf5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md\n",
    "# https://keras.io/callbacks/#tensorboard\n",
    "# http://stackoverflow.com/questions/42112260/how-do-i-use-the-tensorboard-callback-of-keras\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='../tmp/tf_log')\n",
    "#                                          histogram_freq=1, write_graph=True, write_images=True)\n",
    "#                                          histogram_freq=1, write_graph=True, write_images=True)\n",
    "# tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "# To start tensorboard\n",
    "# tensorboard --logdir=/mnt/c/Users/olive/Development/ml/tf_log\n",
    "# open http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to distribute our different classes equally over test and train, this works using stratify\n",
    "# https://github.com/amueller/scipy-2017-sklearn/blob/master/notebooks/04.Training_and_Testing_Data.ipynb\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, stratify=y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3032, 64, 64, 3), (3032, 6))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 58, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 27, 27, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 2,232,454\n",
      "Trainable params: 2,232,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "# drop_out = 0.9\n",
    "# drop_out = 0.75\n",
    "drop_out = 0.5\n",
    "# drop_out = 0.25\n",
    "# drop_out = 0.0\n",
    "\n",
    "# input tensor for a 3-channel 64x64 image\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "\n",
    "# one block of convolutional layers\n",
    "x = Convolution2D(64, 3, 3, activation='relu')(inputs)\n",
    "# x = Dropout(drop_out)(x)\n",
    "x = Convolution2D(64, 3, 3, activation='relu')(x)\n",
    "# x = Dropout(drop_out)(x)\n",
    "x = Convolution2D(64, 3, 3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "\n",
    "# one more block\n",
    "x = Convolution2D(128, 3, 3, activation='relu')(x)\n",
    "# x = Dropout(drop_out)(x)\n",
    "x = Convolution2D(128, 3, 3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "\n",
    "# one more block\n",
    "x = Convolution2D(256, 3, 3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "\n",
    "# softmax activation, 6 categories\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "model = Model(input=inputs, output=predictions)\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf ../tmp/tf_log\n",
    "!rm -rf ../tmp/model-checkpoints\n",
    "\n",
    "!mkdir ../tmp/model-checkpoints\n",
    "!mkdir ../tmp/tf_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31T06:34:45.622357\n",
      "Train on 2122 samples, validate on 910 samples\n",
      "Epoch 1/2000\n",
      "2122/2122 [==============================] - 15s - loss: 3.5236 - acc: 0.1946 - val_loss: 1.7893 - val_acc: 0.1912\n",
      "Epoch 2/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7781 - acc: 0.2055 - val_loss: 1.7771 - val_acc: 0.2000\n",
      "Epoch 3/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7573 - acc: 0.1937 - val_loss: 1.7718 - val_acc: 0.2088\n",
      "Epoch 4/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7570 - acc: 0.2050 - val_loss: 1.7639 - val_acc: 0.2000\n",
      "Epoch 5/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7546 - acc: 0.2125 - val_loss: 1.7478 - val_acc: 0.2000\n",
      "Epoch 6/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.7651 - acc: 0.2276 - val_loss: 1.7855 - val_acc: 0.1714\n",
      "Epoch 7/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.7615 - acc: 0.2323 - val_loss: 1.7489 - val_acc: 0.2363\n",
      "Epoch 8/2000\n",
      "2122/2122 [==============================] - 5s - loss: 2.0125 - acc: 0.2135 - val_loss: 1.7860 - val_acc: 0.1714\n",
      "Epoch 9/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.7723 - acc: 0.2012 - val_loss: 1.7829 - val_acc: 0.1692\n",
      "Epoch 10/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.7508 - acc: 0.2229 - val_loss: 1.7294 - val_acc: 0.2527\n",
      "Epoch 11/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.7576 - acc: 0.2262 - val_loss: 1.7624 - val_acc: 0.2110\n",
      "Epoch 12/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.7361 - acc: 0.2620 - val_loss: 2.3431 - val_acc: 0.1714\n",
      "Epoch 13/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.9842 - acc: 0.2300 - val_loss: 1.7432 - val_acc: 0.2736\n",
      "Epoch 14/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7290 - acc: 0.2380 - val_loss: 1.7254 - val_acc: 0.3198\n",
      "Epoch 15/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7129 - acc: 0.2733 - val_loss: 1.7033 - val_acc: 0.2714\n",
      "Epoch 16/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7128 - acc: 0.2620 - val_loss: 1.8091 - val_acc: 0.1780\n",
      "Epoch 17/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7303 - acc: 0.2394 - val_loss: 1.6931 - val_acc: 0.3066\n",
      "Epoch 18/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6726 - acc: 0.2870 - val_loss: 2.0014 - val_acc: 0.1714\n",
      "Epoch 19/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.8323 - acc: 0.2394 - val_loss: 1.7147 - val_acc: 0.2527\n",
      "Epoch 20/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7298 - acc: 0.2625 - val_loss: 1.7686 - val_acc: 0.1901\n",
      "Epoch 21/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7065 - acc: 0.2710 - val_loss: 1.7703 - val_acc: 0.1890\n",
      "Epoch 22/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6928 - acc: 0.2696 - val_loss: 1.6595 - val_acc: 0.3011\n",
      "Epoch 23/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.9332 - acc: 0.2182 - val_loss: 1.7481 - val_acc: 0.2286\n",
      "Epoch 24/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7491 - acc: 0.2846 - val_loss: 1.7383 - val_acc: 0.2912\n",
      "Epoch 25/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7011 - acc: 0.2828 - val_loss: 1.6962 - val_acc: 0.2802\n",
      "Epoch 26/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6887 - acc: 0.2950 - val_loss: 1.6725 - val_acc: 0.3066\n",
      "Epoch 27/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6733 - acc: 0.2941 - val_loss: 1.7003 - val_acc: 0.3319\n",
      "Epoch 28/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6477 - acc: 0.3063 - val_loss: 1.9137 - val_acc: 0.1802\n",
      "Epoch 29/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7409 - acc: 0.2502 - val_loss: 1.7215 - val_acc: 0.2692\n",
      "Epoch 30/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6993 - acc: 0.2842 - val_loss: 1.6692 - val_acc: 0.3055\n",
      "Epoch 31/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6843 - acc: 0.2851 - val_loss: 1.7196 - val_acc: 0.3121\n",
      "Epoch 32/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6696 - acc: 0.3106 - val_loss: 1.6783 - val_acc: 0.2824\n",
      "Epoch 33/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.6497 - acc: 0.3115 - val_loss: 1.6232 - val_acc: 0.3231\n",
      "Epoch 34/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.7887 - acc: 0.2710 - val_loss: 1.7428 - val_acc: 0.2780\n",
      "Epoch 35/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.6973 - acc: 0.2696 - val_loss: 1.6465 - val_acc: 0.3330\n",
      "Epoch 36/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7180 - acc: 0.2592 - val_loss: 1.7009 - val_acc: 0.3099\n",
      "Epoch 37/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.6376 - acc: 0.3360 - val_loss: 1.6340 - val_acc: 0.3121\n",
      "Epoch 38/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.7266 - acc: 0.2804 - val_loss: 1.7071 - val_acc: 0.3385\n",
      "Epoch 39/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.6530 - acc: 0.3252 - val_loss: 1.6465 - val_acc: 0.2857\n",
      "Epoch 40/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6353 - acc: 0.3106 - val_loss: 1.7685 - val_acc: 0.2341\n",
      "Epoch 41/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7254 - acc: 0.2663 - val_loss: 1.6342 - val_acc: 0.3319\n",
      "Epoch 42/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.6187 - acc: 0.3351 - val_loss: 1.6806 - val_acc: 0.2813\n",
      "Epoch 43/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.6250 - acc: 0.3299 - val_loss: 1.9030 - val_acc: 0.2615\n",
      "Epoch 44/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.9126 - acc: 0.2502 - val_loss: 1.7060 - val_acc: 0.2780\n",
      "Epoch 45/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6495 - acc: 0.2978 - val_loss: 1.6302 - val_acc: 0.3275\n",
      "Epoch 46/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6302 - acc: 0.3318 - val_loss: 1.5875 - val_acc: 0.3374\n",
      "Epoch 47/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6157 - acc: 0.3398 - val_loss: 1.6458 - val_acc: 0.3187\n",
      "Epoch 48/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5689 - acc: 0.3638 - val_loss: 1.6094 - val_acc: 0.3363\n",
      "Epoch 49/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.5526 - acc: 0.3666 - val_loss: 1.7117 - val_acc: 0.2473\n",
      "Epoch 50/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5996 - acc: 0.3374 - val_loss: 1.5387 - val_acc: 0.3527\n",
      "Epoch 51/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6019 - acc: 0.3497 - val_loss: 1.5387 - val_acc: 0.3560\n",
      "Epoch 52/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.5119 - acc: 0.3817 - val_loss: 1.5233 - val_acc: 0.3549\n",
      "Epoch 53/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.7222 - acc: 0.3162 - val_loss: 1.5938 - val_acc: 0.3429\n",
      "Epoch 54/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5259 - acc: 0.3864 - val_loss: 1.7432 - val_acc: 0.2637\n",
      "Epoch 55/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6359 - acc: 0.3398 - val_loss: 1.5687 - val_acc: 0.3495\n",
      "Epoch 56/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5327 - acc: 0.3737 - val_loss: 1.6653 - val_acc: 0.3132\n",
      "Epoch 57/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5414 - acc: 0.3756 - val_loss: 1.5211 - val_acc: 0.3802\n",
      "Epoch 58/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.8755 - acc: 0.3798 - val_loss: 1.6584 - val_acc: 0.3220\n",
      "Epoch 59/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5803 - acc: 0.3709 - val_loss: 1.5245 - val_acc: 0.3549\n",
      "Epoch 60/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.4976 - acc: 0.4034 - val_loss: 1.5222 - val_acc: 0.3604\n",
      "Epoch 61/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.4724 - acc: 0.4128 - val_loss: 1.6951 - val_acc: 0.3253\n",
      "Epoch 62/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5541 - acc: 0.3784 - val_loss: 1.5090 - val_acc: 0.3769\n",
      "Epoch 63/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5508 - acc: 0.4062 - val_loss: 1.5235 - val_acc: 0.3901\n",
      "Epoch 64/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.3823 - acc: 0.4581 - val_loss: 1.5549 - val_acc: 0.3407\n",
      "Epoch 65/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.5157 - acc: 0.3973 - val_loss: 1.4519 - val_acc: 0.3890\n",
      "Epoch 66/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.4651 - acc: 0.4298 - val_loss: 1.6098 - val_acc: 0.3220\n",
      "Epoch 67/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.4436 - acc: 0.4265 - val_loss: 1.4907 - val_acc: 0.3791\n",
      "Epoch 68/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.3317 - acc: 0.4746 - val_loss: 1.5226 - val_acc: 0.4000\n",
      "Epoch 69/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.3902 - acc: 0.4703 - val_loss: 1.6286 - val_acc: 0.3022\n",
      "Epoch 70/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.4841 - acc: 0.3973 - val_loss: 1.4606 - val_acc: 0.4165\n",
      "Epoch 71/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.3190 - acc: 0.5009 - val_loss: 1.8810 - val_acc: 0.3516\n",
      "Epoch 72/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.6465 - acc: 0.3916 - val_loss: 1.4566 - val_acc: 0.4088\n",
      "Epoch 73/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.3499 - acc: 0.4717 - val_loss: 1.4791 - val_acc: 0.4055\n",
      "Epoch 74/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.3198 - acc: 0.4779 - val_loss: 1.3925 - val_acc: 0.4505\n",
      "Epoch 75/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.3181 - acc: 0.4755 - val_loss: 1.4068 - val_acc: 0.4440\n",
      "Epoch 76/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.2746 - acc: 0.5080 - val_loss: 1.4828 - val_acc: 0.3846\n",
      "Epoch 77/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.3251 - acc: 0.4746 - val_loss: 1.3807 - val_acc: 0.4637\n",
      "Epoch 78/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.2819 - acc: 0.5221 - val_loss: 1.5498 - val_acc: 0.4198\n",
      "Epoch 79/2000\n",
      "2122/2122 [==============================] - 4s - loss: 1.2505 - acc: 0.5221 - val_loss: 1.3125 - val_acc: 0.4659\n",
      "Epoch 80/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.1647 - acc: 0.5401 - val_loss: 1.4388 - val_acc: 0.4330\n",
      "Epoch 81/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.3417 - acc: 0.4783 - val_loss: 1.3892 - val_acc: 0.4560\n",
      "Epoch 82/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.3286 - acc: 0.4958 - val_loss: 1.2698 - val_acc: 0.5011\n",
      "Epoch 83/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.1367 - acc: 0.5467 - val_loss: 1.2979 - val_acc: 0.5000\n",
      "Epoch 84/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.1695 - acc: 0.5679 - val_loss: 1.3319 - val_acc: 0.4835\n",
      "Epoch 85/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.0244 - acc: 0.6103 - val_loss: 1.4284 - val_acc: 0.4374\n",
      "Epoch 86/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.2121 - acc: 0.5363 - val_loss: 1.2681 - val_acc: 0.5121\n",
      "Epoch 87/2000\n",
      "2122/2122 [==============================] - 5s - loss: 0.9888 - acc: 0.6225 - val_loss: 1.3423 - val_acc: 0.4593\n",
      "Epoch 88/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.0669 - acc: 0.5914 - val_loss: 1.1569 - val_acc: 0.5484\n",
      "Epoch 89/2000\n",
      "2122/2122 [==============================] - 5s - loss: 0.9675 - acc: 0.6268 - val_loss: 1.2204 - val_acc: 0.5505\n",
      "Epoch 90/2000\n",
      "2122/2122 [==============================] - 5s - loss: 1.0207 - acc: 0.6023 - val_loss: 1.2899 - val_acc: 0.4945\n",
      "Epoch 91/2000\n",
      " 500/2122 [======>.......................] - ETA: 3s - loss: 1.0049 - acc: 0.5860"
     ]
    }
   ],
   "source": [
    "# Running on a GPU bach size might be critical depdendng on the GPU memory available\n",
    "# more is desirable, but we might end up using 50 only \n",
    "print(datetime.utcnow().isoformat())\n",
    "# BE CAREFUL, validation data is always the last data sets and not shuffled\n",
    "# https://keras.io/getting-started/faq/#how-is-the-validation-split-computed\n",
    "model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.3, \n",
    "          callbacks=[tb_callback, early_stopping_callback])\n",
    "#           callbacks=[tb_callback])\n",
    "# model.fit(X_train, y_train, epochs=50, batch_size=200, validation_split=0.3)\n",
    "print(datetime.utcnow().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032/3032 [==============================] - 2s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.26316697995036648, 0.95316629752634696)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, batch_size=500)\n",
    "train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/758 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0037021731323805, 0.81530343589807874)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=500)\n",
    "test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0506060123443604, 0.81530344486236572)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_loss, original_accuracy = model.evaluate(original_images, original_labels, batch_size=500)\n",
    "original_loss, original_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('models/conv-vgg-augmented.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 18M\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 18M Jul 21 19:56 conv-vgg-augmented.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://transfer.sh/K5RH8/conv-vgg-augmented.hdf5"
     ]
    }
   ],
   "source": [
    "!curl --upload-file ./models/conv-vgg-augmented.hdf5 https://transfer.sh/conv-vgg-augmented.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
